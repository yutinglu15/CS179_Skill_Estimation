{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill estimation using Stan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can use a simple **continuous** variable model to predict a hidden \"skill level\" of players based on their performance in a collection of games against each other.  We need data (the games and outcomes), and a model of how skill translates into these outcomes (e.g., higher skilled players have a better chance of winning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use \"stan\" to define the model; this will compile an inference engine which can then perform Monte Carlo (and some other) approximate inference procedures to give estimates.\n",
    "\n",
    "We'll describe the (prior) distribution of skill levels as Gaussian, and then model the probability of Player A winning over Player B as a logistic function of the two players' skill differences, with a scaling coefficient (which we can set or try to learn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             # Total number of players\n",
    "  int<lower=1> E;             # number of games\n",
    "  real<lower=0> scale;        # scale value for probability computation\n",
    "  int<lower=0,upper=1> win[E]; # PA wins vs PB\n",
    "  int PA[E];                  # player info between each game\n",
    "  int PB[E];                  # \n",
    "}\n",
    "parameters {\n",
    "  vector [N] skill;           # skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ skill[i]~normal(0,3); }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ bernoulli_logit( (scale)*(skill[PA[i]]-skill[PB[i]]) );\n",
    "  }   # win probability is a logit function of skill difference\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model.  We'll save a version of it so we don't have to recompile every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "try:     # load it if already compiled\n",
    "    sm = pickle.load(open('skill_model.pkl', 'rb'))\n",
    "except:  # ow, compile and save compiled model\n",
    "    sm = pystan.StanModel(model_code = skill_model)\n",
    "    with open('skill_model.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the observed data: number of players and games, which pairs played each game, and who won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': 3,\n",
    "    'E': 4,\n",
    "    'scale': 0.3,\n",
    "    'win':[1, 1, 1, 0],\n",
    "    'PA': [1, 1, 2, 1],\n",
    "    'PB': [3, 3, 3, 2]\n",
    "}\n",
    "# Player 1 & 3 played & P1 won; then again; then P2 & P3 (P2 wins), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=10000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57593548,  1.832701  , -2.45314344])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['skill'].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to predict which player will win, we might use a direct estimator of that quantity based on the sample values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42315631660497527\n"
     ]
    }
   ],
   "source": [
    "# Player 0 vs Player 1 prediction:\n",
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "# Use our model's win probability function (logistic of scaled difference)\n",
    "#  using the predicted skill difference for each sample:\n",
    "prob = logit( skill_data['scale']*(samples['skill'][:,0]-samples['skill'][:,1]) ).mean()\n",
    "\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
