{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill estimation using Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(66)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model that defined skill's distribution with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             // Total number of players\n",
    "  int<lower=1> E;             // number of games\n",
    "  real<lower=0> scale;        // scale value for probability computation\n",
    "  int<lower=0,upper=1> win[E]; // PA wins vs PB\n",
    "  int PA[E];                  // player info between each game\n",
    "  int PB[E];                  // \n",
    "  real scores[E];              // scores for each game\n",
    "}\n",
    "parameters {\n",
    "  vector [N] skill;           // skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ skill[i]~normal(0,3); }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ bernoulli_logit( (scale)*(skill[PA[i]]-skill[PB[i]]) );\n",
    "    scores[i] ~ gamma( fabs(skill[PA[i]] - skill[PB[i]]) + 2, 0.5 );\n",
    "  }   // win probability is a logit function of skill difference\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel(model_code = skill_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_model_scores_diff.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:     # load it if already compiled\n",
    "#     sm = pickle.load(open('skill_model_scores.pkl', 'rb'))\n",
    "# except:  # ow, compile and save compiled model\n",
    "#     sm = pystan.StanModel(model_code = skill_model)\n",
    "#     with open('skill_model_scores.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='train'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    p = 0\n",
    "    playerid = {}\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10: \n",
    "            continue   # parse error or blank line\n",
    "        player0,player1 = csv[1],csv[4]\n",
    "        if player0 not in playerid:\n",
    "            playerid[player0]=p\n",
    "            p+=1\n",
    "        if player1 not in playerid:\n",
    "            playerid[player1]=p\n",
    "            p+=1\n",
    "\n",
    "    \n",
    "    # Sparsifying parameters (discard some training examples):\n",
    "    # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "    # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "    # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "\n",
    "    wins = []\n",
    "    playerA, playerB = [], []\n",
    "    raceA, raceB = [], []\n",
    "    nplayers = len(playerid)\n",
    "    nplays = np.zeros( (nplayers,nplayers) )\n",
    "    race = {'P':0, 'T':1, 'Z':2}\n",
    "    scoresA = []\n",
    "    scoresB = []\n",
    "    scores = []\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10 or csv[6] == 'R' or csv[7] == 'R':\n",
    "            continue   # parse error or blank line\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a]+=1\n",
    "                \n",
    "                playerA.append(a+1)\n",
    "                playerB.append(b+1)\n",
    "                wins.append(1 if aw else 0) \n",
    "                raceA.append(race[csv[6]])\n",
    "                raceB.append(race[csv[7]])\n",
    "                sa, sb = csv[3].split('â€“')\n",
    "                scores.append(abs(int(sa)-int(sb)))\n",
    "#                 scores.append((int(sa)-int(sb)))\n",
    "                scoresA.append(int(sa))\n",
    "                scoresB.append(int(sb))\n",
    "\n",
    "    return playerid,nplayers,playerA,playerB,raceA, raceB, wins, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerid,nplayers,playerA,playerB,raceA, raceB, wins, scores = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: \n",
      "# players 999\n",
      "# games 4678\n",
      "player A [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "player B [2, 3, 4, 5, 6, 7, 8, 9, 10, 9]\n",
      "wins [0, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
      "scores [2, 1, 2, 1, 1, 1, 1, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print('summary: ')\n",
    "print('# players', nplayers)\n",
    "print('# games', len(wins))\n",
    "print('player A', playerA[:10])\n",
    "print('player B', playerB[:10])\n",
    "print('wins', wins[:10])\n",
    "print('scores', scores[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the observed data: number of players and games, which pairs played each game, and who won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': nplayers,\n",
    "    'E': len(wins),\n",
    "    'scale': 0.4,\n",
    "    'win':wins,\n",
    "    'PA': playerA,\n",
    "    'PB': playerB,\n",
    "    'scores': scores\n",
    "}\n",
    "# Player 1 & 3 played & P1 won; then again; then P2 & P3 (P2 wins), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=2000, chains=4, n_jobs = 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('skill',\n",
       "              array([[-0.01410025, -0.22270211,  0.08216647, ..., -0.25304753,\n",
       "                      -0.8986737 , -0.58046078],\n",
       "                     [ 0.18652951,  0.04970448,  0.17656142, ...,  0.53103764,\n",
       "                       1.05356926,  0.20388716],\n",
       "                     [ 0.26069781,  0.34515435,  0.42268362, ...,  0.26069943,\n",
       "                      -0.2814254 , -0.19252609],\n",
       "                     ...,\n",
       "                     [ 0.07332413,  0.1192781 ,  0.21281536, ...,  0.02751995,\n",
       "                      -0.03330764,  0.09360843],\n",
       "                     [-0.04506887, -0.32122863, -0.0713199 , ..., -0.35967077,\n",
       "                       0.74461244, -0.05583605],\n",
       "                     [ 0.05827586, -0.04482001,  0.16566944, ..., -0.60075256,\n",
       "                       0.03987125, -0.18841636]])),\n",
       "             ('lp__',\n",
       "              array([-8634.39650095, -8658.82599988, -8621.43229158, ...,\n",
       "                     -8658.70307676, -8622.33324285, -8618.4230522 ]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 999)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['skill'].shape # 2*100 iterations? 999 players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to save the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_hat_scores_diff.pkl', 'wb') as f: \n",
    "    pickle.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = pickle.load(open('skill_hat_scores_diff.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = skill_hat['skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid_data(playerid, dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='valid'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "\n",
    "  # Sparsifying parameters (discard some training examples):\n",
    "  # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "  # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "  # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "    \n",
    "    games = []\n",
    "    race = {'P':0, 'T':1, 'Z':2}\n",
    "    nplays, nwins = np.zeros( (nplayers,nplayers) ), np.zeros( (nplayers,nplayers) )\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10 or csv[6] == 'R' or csv[7] == 'R':\n",
    "            continue   # parse error or blank line\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a]+=1\n",
    "                nwins[a,b] += aw\n",
    "                nwins[b,a] += bw\n",
    "                games.append((a,b,aw,race[csv[6]],race[csv[7]]))\n",
    "    \n",
    "    return nplayers, nplays, nwins, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplayers_val, nplays_val, nwins_val, games_val = load_valid_data(playerid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:  999\n",
      "(999, 999) 9542.0\n",
      "(999, 999) 4788.0\n",
      "games 4771\n"
     ]
    }
   ],
   "source": [
    "print('summary: ', nplayers_val)\n",
    "print(nplays_val.shape, nplays_val.sum())\n",
    "print(nwins_val.shape, nwins_val.sum())\n",
    "print('games', len(games_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "def prediction_loss(skill, nplayers, nplays, nwins, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    binary_loss = 0.\n",
    "    for i in range(nplayers):\n",
    "        for j in range(i+1, nplayers):\n",
    "            if nplays[i, j] == 0:\n",
    "                continue\n",
    "            prob = nwins[i,j] / nplays[i,j]\n",
    "            prob_hat = logit( skill_data['scale']*(skill[:,i]-skill[:,j]) ).mean()\n",
    "            loss += np.abs(prob_hat - prob)\n",
    "            binary_loss += np.logical_xor(prob_hat >= 0.5, prob >= 0.5)\n",
    "    \n",
    "    loss /= (nplays > 0).sum()/2\n",
    "    binary_loss /= (nplays > 0).sum()/2\n",
    "    \n",
    "    return loss, binary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = prediction_loss(skill_hat, nplayers_val, nplays_val, nwins_val, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45426590510171844, 0.18932527693857)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_per_game(skill, games):\n",
    "    \n",
    "    loss = 0.\n",
    "\n",
    "    for game in games:\n",
    "        a, b, w, ra,rb = game\n",
    "        prob_hat = logit( skill_data['scale']*(skill[:,a]-skill[:,b]) ).mean()\n",
    "        loss += np.logical_xor(prob_hat >= 0.5, w)\n",
    "\n",
    "    loss /= len(games)\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22783483546426325"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_per_game(skill_hat, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
