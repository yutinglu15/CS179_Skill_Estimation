{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill estimation using Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(66)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model that defined skill's distribution with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             // Total number of players\n",
    "  int<lower=1> E;             // number of games\n",
    "  real<lower=0> scale;        // scale value for probability computation\n",
    "  int<lower=0,upper=1> win[E]; // PA wins vs PB\n",
    "  int PA[E];                  // player info between each game\n",
    "  int PB[E];                  // \n",
    "  int SA[E];              // scores for each game\n",
    "  int SB[E];\n",
    "}\n",
    "parameters {\n",
    "  vector [N] Oskill;           // skill values for each player\n",
    "  vector [N] Dskill;           // skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ \n",
    "    Oskill[i]~normal(0,3); \n",
    "    Dskill[i]~normal(0,3); \n",
    "  }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ bernoulli_logit( (scale)*(Oskill[PA[i]]+Dskill[PA[i]]-Oskill[PB[i]]-Dskill[PB[i]]) );\n",
    "    SA[i] ~ poisson( 0.5* (Oskill[PA[i]]*0.3 + 1) + 0.5* (Dskill[PB[i]]*0.3 + 1) );\n",
    "    SA[i] ~ poisson( 0.5* (Dskill[PA[i]]*0.3 + 1) + 0.5* (Oskill[PB[i]]*0.3 + 1) );\n",
    "  }   // win probability is a logit function of skill difference\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if (skill[PA[i]]*0.3 + 1 > 0){SA[i] ~ poisson( skill[PA[i]]*0.3 + 1 );}\n",
    "    if (skill[PB[i]]*0.3 + 1 > 0){SB[i] ~ poisson( skill[PB[i]]*0.3 + 1 );}\n",
    "    \n",
    "    \n",
    "    SA[i] ~ poisson( fabs(skill[PA[i]]*0.3 + 1) );\n",
    "    SB[i] ~ poisson( fabs(skill[PB[i]]*0.3 + 1) );    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel(model_code = skill_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_model_scores_od.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:     # load it if already compiled\n",
    "#     sm = pickle.load(open('skill_model_scores.pkl', 'rb'))\n",
    "# except:  # ow, compile and save compiled model\n",
    "#     sm = pystan.StanModel(model_code = skill_model)\n",
    "#     with open('skill_model_scores.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='train'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    p = 0\n",
    "    playerid = {}\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10: \n",
    "            continue   # parse error or blank line\n",
    "        player0,player1 = csv[1],csv[4]\n",
    "        if player0 not in playerid:\n",
    "            playerid[player0]=p\n",
    "            p+=1\n",
    "        if player1 not in playerid:\n",
    "            playerid[player1]=p\n",
    "            p+=1\n",
    "\n",
    "    \n",
    "    # Sparsifying parameters (discard some training examples):\n",
    "    # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "    # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "    # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "\n",
    "    wins = []\n",
    "    playerA, playerB = [], []\n",
    "    raceA, raceB = [], []\n",
    "    nplayers = len(playerid)\n",
    "    nplays = np.zeros( (nplayers,nplayers) )\n",
    "    race = {'P':0, 'T':1, 'Z':2}\n",
    "    scoresA = []\n",
    "    scoresB = []\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10 or csv[6] == 'R' or csv[7] == 'R':\n",
    "            continue   # parse error or blank line\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a]+=1\n",
    "                \n",
    "                playerA.append(a+1)\n",
    "                playerB.append(b+1)\n",
    "                wins.append(1 if aw else 0) \n",
    "                raceA.append(race[csv[6]])\n",
    "                raceB.append(race[csv[7]])\n",
    "                sa, sb = csv[3].split('–')\n",
    "#                 scores.append(abs(int(sa)-int(sb)))\n",
    "#                 scores.append((int(sa)-int(sb)))\n",
    "                scoresA.append(int(sa))\n",
    "                scoresB.append(int(sb))\n",
    "\n",
    "    return playerid,nplayers,playerA,playerB,raceA, raceB, wins, scoresA, scoresB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerid,nplayers,playerA,playerB,raceA, raceB, wins, scoresA, scoresB = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: \n",
      "# players 999\n",
      "# games 4678\n",
      "player A [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "player B [2, 3, 4, 5, 6, 7, 8, 9, 10, 9]\n",
      "wins [0, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
      "raceA [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "raceB [0, 2, 1, 2, 0, 1, 2, 0, 1, 0]\n",
      "scoresA [0, 1, 0, 0, 1, 1, 1, 0, 0, 2]\n",
      "scoresB [2, 2, 2, 1, 0, 0, 0, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print('summary: ')\n",
    "print('# players', nplayers)\n",
    "print('# games', len(wins))\n",
    "print('player A', playerA[:10])\n",
    "print('player B', playerB[:10])\n",
    "print('wins', wins[:10])\n",
    "print('raceA', raceA[:10])\n",
    "print('raceB', raceB[:10])\n",
    "print('scoresA', scoresA[:10])\n",
    "print('scoresB', scoresB[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the observed data: number of players and games, which pairs played each game, and who won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': nplayers,\n",
    "    'E': len(wins),\n",
    "    'scale': 0.5,\n",
    "    'win':wins,\n",
    "    'PA': playerA,\n",
    "    'PB': playerB,\n",
    "    'SA': scoresA,\n",
    "    'SB': scoresB\n",
    "}\n",
    "# Player 1 & 3 played & P1 won; then again; then P2 & P3 (P2 wins), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING: 1763 of 4000 iterations ended with a divergence (44.1 %).\n",
      "WARNING: Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    }
   ],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=2000, chains=4, n_jobs = 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Oskill',\n",
       "              array([[ 3.10987855,  3.07910513,  3.57866991, ..., -2.12176347,\n",
       "                      -0.21234289,  0.94227044],\n",
       "                     [ 2.8760383 ,  1.54664135,  3.52521589, ...,  0.98287329,\n",
       "                      -2.40320867, -2.85290136],\n",
       "                     [ 2.62659558,  3.9650973 ,  3.78805072, ..., -1.32505344,\n",
       "                       1.65365377,  2.47973864],\n",
       "                     ...,\n",
       "                     [ 2.86214885,  0.75076162,  3.05024296, ..., -0.63169938,\n",
       "                      -2.60716814, -4.05042055],\n",
       "                     [ 2.73074592,  3.70491768,  4.07267822, ..., -0.172873  ,\n",
       "                      -0.22654381, -1.19665237],\n",
       "                     [ 3.00232699,  4.55735324,  3.61558307, ...,  1.23382154,\n",
       "                      -2.11008159, -1.87000167]])),\n",
       "             ('Dskill',\n",
       "              array([[ 2.00190766,  2.00793081,  2.60793041, ...,  2.49949147,\n",
       "                       1.19029761,  0.08192097],\n",
       "                     [ 2.148987  ,  3.29077612,  3.73704185, ..., -2.73164245,\n",
       "                       3.8305035 ,  0.78276205],\n",
       "                     [ 2.58589671,  1.48598319,  2.19441844, ...,  2.4471692 ,\n",
       "                      -1.17672808, -4.43135189],\n",
       "                     ...,\n",
       "                     [ 2.41912333,  5.57674062,  4.34444312, ...,  2.57778029,\n",
       "                       0.94174975,  3.69224669],\n",
       "                     [ 2.37370217,  4.65337157,  4.24112123, ..., -1.99974349,\n",
       "                      -3.29407849,  0.0944751 ],\n",
       "                     [ 2.12765274,  1.99583846,  4.11835427, ...,  2.84125382,\n",
       "                       0.57233603, -3.29787504]])),\n",
       "             ('lp__',\n",
       "              array([-10866.52153028, -10848.66574945, -10851.12689409, ...,\n",
       "                     -10798.97031259, -10801.90766827, -10766.44937478]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 999)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['Oskill'].shape # 2*100 iterations? 999 players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to save the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_hat_scores_od.pkl', 'wb') as f: \n",
    "    pickle.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = pickle.load(open('skill_hat_scores_od.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oskill_hat = skill_hat[\"Oskill\"]\n",
    "Dskill_hat = skill_hat[\"Dskill\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid_data(playerid,dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='valid'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "\n",
    "  # Sparsifying parameters (discard some training examples):\n",
    "  # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "  # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "  # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "    \n",
    "    games = []\n",
    "    race = {'P':0, 'T':1, 'Z':2}\n",
    "    nplays, nwins = np.zeros( (nplayers,nplayers) ), np.zeros( (nplayers,nplayers) )\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10 or csv[6] == 'R' or csv[7] == 'R':\n",
    "            continue   # parse error or blank line\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a]+=1\n",
    "                nwins[a,b] += aw\n",
    "                nwins[b,a] += bw\n",
    "                \n",
    "                sa, sb = csv[3].split('–')\n",
    "#                 scores.append(abs(int(sa)-int(sb)))\n",
    "#                 scores.append((int(sa)-int(sb)))\n",
    "                scoresA.append(int(sa))\n",
    "                scoresB.append(int(sb))\n",
    "                games.append((a,b,aw,sa,sb))\n",
    "    \n",
    "    \n",
    "    return nplayers, nplays, nwins, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplayers_val, nplays_val, nwins_val, games_val = load_valid_data(playerid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:  999\n",
      "(999, 999) 9542.0\n",
      "(999, 999) 4788.0\n",
      "games 4771\n"
     ]
    }
   ],
   "source": [
    "print('summary: ', nplayers_val)\n",
    "print(nplays_val.shape, nplays_val.sum())\n",
    "print(nwins_val.shape, nwins_val.sum())\n",
    "print('games', len(games_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "def prediction_loss(oskill, dskill, nplayers, nplays, nwins, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    binary_loss = 0.\n",
    "    for i in range(nplayers):\n",
    "        for j in range(i+1, nplayers):\n",
    "            if nplays[i, j] == 0:\n",
    "                continue\n",
    "            prob = nwins[i,j] / nplays[i,j]\n",
    "            prob_hat = logit( skill_data['scale']*(oskill[:,i]+dskill[:,i]-oskill[:,j]-dskill[:,j]) ).mean()\n",
    "            loss += np.abs(prob_hat - prob)\n",
    "            binary_loss += np.logical_xor(prob_hat >= 0.5, prob >= 0.5)\n",
    "            \n",
    "\n",
    "    \n",
    "    loss /= (nplays > 0).sum()/2\n",
    "    binary_loss /= (nplays > 0).sum()/2\n",
    "    \n",
    "    return loss, binary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = prediction_loss(Oskill_hat, Dskill_hat,nplayers_val, nplays_val, nwins_val, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25937176313460397, 0.17891910036925143)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_per_game(oskill, dskill, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    \n",
    "    for game in games:\n",
    "        a, b, w, sa, sb = game\n",
    "        prob_hat = logit( skill_data['scale']*(oskill[:,a]+dskill[:,a]-oskill[:,b]-dskill[:,b]) ).mean()\n",
    "        loss += np.logical_xor(prob_hat >= 0.5, w)\n",
    "        \n",
    "    loss /= len(games)*2\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10909662544539929"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_per_game(Oskill_hat, Dskill_hat, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
