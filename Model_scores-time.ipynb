{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill estimation using Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(66)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model that defined skill's distribution with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             // Total number of players\n",
    "  int<lower=1> E;             // number of games\n",
    "  real<lower=0> scale;        // scale value for probability computation\n",
    "  int<lower=0,upper=1> win[E]; // PA wins vs PB\n",
    "  int PA[E];                  // player info between each game\n",
    "  int PB[E];                  // \n",
    "  real MA[E];                  // # Match\n",
    "  real MB[E];                  //\n",
    "  real growth;                // growth rate with time\n",
    "}\n",
    "parameters {\n",
    "  vector [N] skill;           // skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ skill[i]~normal(0,3); }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ bernoulli_logit( (scale)*(skill[PA[i]]*pow(growth, MA[i])-skill[PB[i]]*pow(growth, MB[i])) );\n",
    "  }   // win probability is a logit function of skill difference\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel(model_code = skill_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_model_scores_time.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:     # load it if already compiled\n",
    "    sm = pickle.load(open('skill_model_scores_time.pkl', 'rb'))\n",
    "except:  # ow, compile and save compiled model\n",
    "    sm = pystan.StanModel(model_code = skill_model)\n",
    "    with open('skill_model_scores_time.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='train'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    p = 0\n",
    "    playerid = {}\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10: \n",
    "            continue   # parse error or blank line\n",
    "        player0,player1 = csv[1],csv[4]\n",
    "        if player0 not in playerid:\n",
    "            playerid[player0]=p\n",
    "            p+=1\n",
    "        if player1 not in playerid:\n",
    "            playerid[player1]=p\n",
    "            p+=1\n",
    "\n",
    "    \n",
    "    # Sparsifying parameters (discard some training examples):\n",
    "    # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "    # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "    # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "\n",
    "    wins = []\n",
    "    playerA, playerB = [], []\n",
    "    nplayers = len(playerid)\n",
    "    nplays = np.zeros( (nplayers,nplayers) )\n",
    "    scoresA = []\n",
    "    scoresB = []\n",
    "    scores = []\n",
    "    \n",
    "    matchA = []\n",
    "    matchB = [] \n",
    "    \n",
    "    train = pd.read_csv(dir+opt+'.csv', header = None)\n",
    "    for i, csv in sorted(train.iterrows(), reverse = True, key=lambda date: datetime.strptime(date[1][0], \"%m/%d/%Y\")):\n",
    "\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                \n",
    "                matchA.append( nplays[a,:].sum() )\n",
    "                matchB.append( nplays[b,:].sum() )\n",
    "                \n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a] += 1\n",
    "                \n",
    "                playerA.append(a+1)\n",
    "                playerB.append(b+1)\n",
    "                wins.append(1 if aw else 0) \n",
    "                sa, sb = csv[3].split('â€“')\n",
    "                scores.append(abs(int(sa)-int(sb)))\n",
    "                scoresA.append(int(sa))\n",
    "                scoresB.append(int(sb))\n",
    "\n",
    "    return playerid, nplayers,playerA,playerB, matchA, matchB, wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerid, nplayers,playerA,playerB, matchA, matchB, wins = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: \n",
      "# players 999\n",
      "# games 4540\n",
      "player A [208, 4, 2, 204, 204, 10, 153, 213, 13, 215]\n",
      "player B [153, 2, 4, 422, 471, 215, 208, 13, 213, 10]\n",
      "wins [1, 0, 1, 1, 1, 1, 0, 1, 0, 0]\n",
      "matchA [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]\n",
      "matchB [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('summary: ')\n",
    "print('# players', nplayers)\n",
    "print('# games', len(wins))\n",
    "print('player A', playerA[:10])\n",
    "print('player B', playerB[:10])\n",
    "print('wins', wins[:10])\n",
    "print('matchA', matchA[:10])\n",
    "print('matchB', matchB[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the observed data: number of players and games, which pairs played each game, and who won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': nplayers,\n",
    "    'E': len(wins),\n",
    "    'scale': 0.4,\n",
    "    'win':wins,\n",
    "    'PA': playerA,\n",
    "    'PB': playerB,\n",
    "    'MA': matchA,\n",
    "    'MB': matchB,\n",
    "    'growth': 1.01\n",
    "}\n",
    "# Player 1 & 3 played & P1 won; then again; then P2 & P3 (P2 wins), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=2000, chains=4, n_jobs = 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('skill',\n",
       "              array([[ 2.09890554e+00,  7.26073153e+00,  7.38194702e+00, ...,\n",
       "                      -1.16922242e+00,  1.79290281e+00, -6.40331629e+00],\n",
       "                     [ 1.25303277e-01,  5.82859798e+00,  4.51359966e+00, ...,\n",
       "                      -3.32195917e+00, -2.17391585e+00, -3.86180470e+00],\n",
       "                     [-1.74711700e+00,  8.62507701e+00,  4.30290818e+00, ...,\n",
       "                      -1.38580596e+00, -2.55856088e+00,  2.77465166e-01],\n",
       "                     ...,\n",
       "                     [-1.49955602e+00,  6.13445775e+00,  2.27901943e+00, ...,\n",
       "                      -5.68344160e-03, -1.79509557e+00, -2.59900569e-01],\n",
       "                     [-2.11546820e-01,  8.72338946e+00,  5.93109725e+00, ...,\n",
       "                       6.43264647e-01, -5.48770645e+00,  3.30001573e-01],\n",
       "                     [-2.63411810e+00,  3.95774154e+00,  3.65558269e+00, ...,\n",
       "                      -1.17791988e+00, -2.96004692e+00, -2.19821345e+00]])),\n",
       "             ('lp__',\n",
       "              array([-2527.76670758, -2517.56529484, -2566.4113617 , ...,\n",
       "                     -2526.47287006, -2551.46199072, -2509.27011658]))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 999)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['skill'].shape # 2*100 iterations? 999 players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to save the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_hat_time.pkl', 'wb') as f: \n",
    "    pickle.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = pickle.load(open('skill_hat_time.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = skill_hat['skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid_data(playerid, dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='valid'):\n",
    "        \n",
    "  # Sparsifying parameters (discard some training examples):\n",
    "  # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "  # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "  # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "    \n",
    "    games = []\n",
    "    nplays, nwins = np.zeros( (nplayers,nplayers) ), np.zeros( (nplayers,nplayers) )\n",
    "    \n",
    "    valid = pd.read_csv(dir+opt+'.csv', header = None)\n",
    "    for i, csv in sorted(valid.iterrows(), reverse = True, key=lambda date: datetime.strptime(date[1][0], \"%m/%d/%Y\")):\n",
    "    \n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a] += 1\n",
    "                nwins[a,b] += aw\n",
    "                nwins[b,a] += bw\n",
    "                games.append((a,b,aw,nplays[a,:].sum(),nplays[b,:].sum()))\n",
    "    \n",
    "    return nplayers, nplays, nwins, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplayers_val, nplays_val, nwins_val, games_val = load_valid_data(playerid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:  999\n",
      "(999, 999) 9362.0\n",
      "(999, 999) 4687.0\n",
      "games 4681\n"
     ]
    }
   ],
   "source": [
    "print('summary: ', nplayers_val)\n",
    "print(nplays_val.shape, nplays_val.sum())\n",
    "print(nwins_val.shape, nwins_val.sum())\n",
    "print('games', len(games_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "def prediction_loss(skill, nplayers, nplays, nwins, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    binary_loss = 0.\n",
    "    for i in range(nplayers):\n",
    "        for j in range(i+1, nplayers):\n",
    "            if nplays[i, j] == 0:\n",
    "                continue\n",
    "            prob = nwins[i,j] / nplays[i,j]\n",
    "            prob_hat = logit( skill_data['scale']*(skill[:,i]-skill[:,j]) ).mean()\n",
    "            loss += np.abs(prob_hat - prob)\n",
    "            binary_loss += np.logical_xor(prob_hat >= 0.5, prob >= 0.5)\n",
    "    \n",
    "    loss /= (nplays > 0).sum()/2\n",
    "    binary_loss /= (nplays > 0).sum()/2\n",
    "    \n",
    "    return loss, binary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = prediction_loss(skill_hat, nplayers_val, nplays_val, nwins_val, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3972375839869985, 0.33345615327929257)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "def loss(skill, nplayers, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    binary_loss = 0.\n",
    "    for game in games:\n",
    "        a, b, w, ma, mb = game\n",
    "        \n",
    "        prob_hat = logit( skill_data['scale']*(skill[:,a]*skill_data['growth']**ma-skill[:,b]*skill_data['growth']**mb) ).mean()\n",
    "        binary_loss += np.logical_xor(prob_hat >= 0.5, w)\n",
    "    \n",
    "\n",
    "    binary_loss /= len(games)\n",
    "    \n",
    "    return binary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3351847895748772"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(skill_hat, nplayers_val, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
