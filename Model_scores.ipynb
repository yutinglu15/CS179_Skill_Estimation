{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill estimation using Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(66)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model that defined skill's distribution with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             // Total number of players\n",
    "  int<lower=1> E;             // number of games\n",
    "  real<lower=0> scale;        // scale value for probability computation\n",
    "  int<lower=0,upper=1> win[E]; // PA wins vs PB\n",
    "  int PA[E];                  // player info between each game\n",
    "  int PB[E];                  // \n",
    "  int SA[E];              // scores for each game\n",
    "  int SB[E];\n",
    "}\n",
    "parameters {\n",
    "  vector [N] skill;           // skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ skill[i]~normal(0,3); }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ bernoulli_logit( (scale)*(skill[PA[i]]-skill[PB[i]]) );\n",
    "    if (skill[PA[i]]*0.3 + 1 > 0){SA[i] ~ poisson( skill[PA[i]]*0.3 + 1 );}\n",
    "    if (skill[PB[i]]*0.3 + 1 > 0){SB[i] ~ poisson( skill[PB[i]]*0.3 + 1 );}\n",
    "  }   // win probability is a logit function of skill difference\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if (skill[PA[i]]*0.3 + 1 > 0){SA[i] ~ poisson( skill[PA[i]]*0.3 + 1 );}\n",
    "    if (skill[PB[i]]*0.3 + 1 > 0){SB[i] ~ poisson( skill[PB[i]]*0.3 + 1 );}\n",
    "    \n",
    "    \n",
    "    SA[i] ~ poisson( fabs(skill[PA[i]]*0.3 + 1) );\n",
    "    SB[i] ~ poisson( fabs(skill[PB[i]]*0.3 + 1) );    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel(model_code = skill_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_model_scores.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:     # load it if already compiled\n",
    "#     sm = pickle.load(open('skill_model_scores.pkl', 'rb'))\n",
    "# except:  # ow, compile and save compiled model\n",
    "#     sm = pystan.StanModel(model_code = skill_model)\n",
    "#     with open('skill_model_scores.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='train'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    p = 0\n",
    "    playerid = {}\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10: \n",
    "            continue   # parse error or blank line\n",
    "        player0,player1 = csv[1],csv[4]\n",
    "        if player0 not in playerid:\n",
    "            playerid[player0]=p\n",
    "            p+=1\n",
    "        if player1 not in playerid:\n",
    "            playerid[player1]=p\n",
    "            p+=1\n",
    "\n",
    "    \n",
    "    # Sparsifying parameters (discard some training examples):\n",
    "    # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "    # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "    # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "\n",
    "    wins = []\n",
    "    playerA, playerB = [], []\n",
    "    raceA, raceB = [], []\n",
    "    nplayers = len(playerid)\n",
    "    nplays = np.zeros( (nplayers,nplayers) )\n",
    "    race = {'P':0, 'T':1, 'Z':2}\n",
    "    scoresA = []\n",
    "    scoresB = []\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10 or csv[6] == 'R' or csv[7] == 'R':\n",
    "            continue   # parse error or blank line\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a]+=1\n",
    "                \n",
    "                playerA.append(a+1)\n",
    "                playerB.append(b+1)\n",
    "                wins.append(1 if aw else 0) \n",
    "                raceA.append(race[csv[6]])\n",
    "                raceB.append(race[csv[7]])\n",
    "                sa, sb = csv[3].split('â€“')\n",
    "#                 scores.append(abs(int(sa)-int(sb)))\n",
    "#                 scores.append((int(sa)-int(sb)))\n",
    "                scoresA.append(int(sa))\n",
    "                scoresB.append(int(sb))\n",
    "\n",
    "    return playerid,nplayers,playerA,playerB,raceA, raceB, wins, scoresA, scoresB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerid,nplayers,playerA,playerB,raceA, raceB, wins, scoresA, scoresB = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: \n",
      "# players 999\n",
      "# games 4678\n",
      "player A [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "player B [2, 3, 4, 5, 6, 7, 8, 9, 10, 9]\n",
      "wins [0, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
      "raceA [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "raceB [0, 2, 1, 2, 0, 1, 2, 0, 1, 0]\n",
      "scoresA [0, 1, 0, 0, 1, 1, 1, 0, 0, 2]\n",
      "scoresB [2, 2, 2, 1, 0, 0, 0, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print('summary: ')\n",
    "print('# players', nplayers)\n",
    "print('# games', len(wins))\n",
    "print('player A', playerA[:10])\n",
    "print('player B', playerB[:10])\n",
    "print('wins', wins[:10])\n",
    "print('raceA', raceA[:10])\n",
    "print('raceB', raceB[:10])\n",
    "print('scoresA', scoresA[:10])\n",
    "print('scoresB', scoresB[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the observed data: number of players and games, which pairs played each game, and who won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': nplayers,\n",
    "    'E': len(wins),\n",
    "    'scale': 0.5,\n",
    "    'win':wins,\n",
    "    'PA': playerA,\n",
    "    'PB': playerB,\n",
    "    'SA': scoresA,\n",
    "    'SB': scoresB\n",
    "}\n",
    "# Player 1 & 3 played & P1 won; then again; then P2 & P3 (P2 wins), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING: Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING: 48 of 4000 iterations ended with a divergence (1.2 %).\n",
      "WARNING: Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "WARNING: 3952 of 4000 iterations saturated the maximum tree depth of 10 (98.8 %)\n",
      "WARNING: Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    }
   ],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=2000, chains=4, n_jobs = 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('skill',\n",
       "              array([[ 1.67208284,  3.11666643,  3.73705795, ..., -8.10203255,\n",
       "                      -0.86255959, -0.45296302],\n",
       "                     [ 1.62864557,  2.79543307,  4.0622911 , ..., -8.11538916,\n",
       "                      -0.20072909, -0.27095842],\n",
       "                     [ 1.54899386,  2.5547274 ,  3.73025306, ..., -7.9237259 ,\n",
       "                      -0.08645157, -0.30769752],\n",
       "                     ...,\n",
       "                     [ 1.7508092 ,  0.96687758,  2.06992011, ..., -3.89341279,\n",
       "                      -1.07046627, -2.46226095],\n",
       "                     [ 1.75120358,  1.02881859,  2.3823339 , ..., -3.66886147,\n",
       "                      -1.1556531 , -2.41340684],\n",
       "                     [ 1.74052672,  0.97821856,  2.08125552, ..., -3.54860807,\n",
       "                      -1.32271144, -2.36110503]])),\n",
       "             ('lp__',\n",
       "              array([-9509.43735666, -9513.39258552, -9494.015467  , ...,\n",
       "                     -9490.09318035, -9489.99649636, -9490.57315838]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['skill'].shape # 2*100 iterations? 999 players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to save the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skill_hat_scores.pkl', 'wb') as f: \n",
    "    pickle.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = pickle.load(open('skill_hat_scores.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_hat = skill_hat['skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid_data(playerid,dir='data/', pKeep=1.0, nEdge=3, nKeep=5, opt='valid'):\n",
    "    with open(dir+opt+'.csv', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "\n",
    "  # Sparsifying parameters (discard some training examples):\n",
    "  # pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "  # nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "  # nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "    \n",
    "    games = []\n",
    "    race = {'P':0, 'T':1, 'Z':2}\n",
    "    nplays, nwins = np.zeros( (nplayers,nplayers) ), np.zeros( (nplayers,nplayers) )\n",
    "    for i in range(len(lines)):\n",
    "        csv = lines[i].split(',')\n",
    "        if len(csv) != 10 or csv[6] == 'R' or csv[7] == 'R':\n",
    "            continue   # parse error or blank line\n",
    "        a,b = playerid[csv[1]],playerid[csv[4]]\n",
    "        aw,bw = csv[2]=='[winner]',csv[5]=='[winner]'\n",
    "        \n",
    "        if (np.random.rand() < pKeep):\n",
    "            if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "                nplays[a,b] += 1\n",
    "                nplays[b,a]+=1\n",
    "                nwins[a,b] += aw\n",
    "                nwins[b,a] += bw\n",
    "                \n",
    "                sa, sb = csv[3].split('â€“')\n",
    "#                 scores.append(abs(int(sa)-int(sb)))\n",
    "#                 scores.append((int(sa)-int(sb)))\n",
    "                scoresA.append(int(sa))\n",
    "                scoresB.append(int(sb))\n",
    "                games.append((a,b,aw,sa,sb))\n",
    "    \n",
    "    \n",
    "    return nplayers, nplays, nwins, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplayers_val, nplays_val, nwins_val, games_val = load_valid_data(playerid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:  999\n",
      "(999, 999) 9542.0\n",
      "(999, 999) 4788.0\n",
      "games 4771\n"
     ]
    }
   ],
   "source": [
    "print('summary: ', nplayers_val)\n",
    "print(nplays_val.shape, nplays_val.sum())\n",
    "print(nwins_val.shape, nwins_val.sum())\n",
    "print('games', len(games_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "def prediction_loss(skill, nplayers, nplays, nwins, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    binary_loss = 0.\n",
    "    for i in range(nplayers):\n",
    "        for j in range(i+1, nplayers):\n",
    "            if nplays[i, j] == 0:\n",
    "                continue\n",
    "            prob = nwins[i,j] / nplays[i,j]\n",
    "            prob_hat = logit( skill_data['scale']*(skill[:,i]-skill[:,j]) ).mean()\n",
    "            loss += np.abs(prob_hat - prob)\n",
    "            binary_loss += np.logical_xor(prob_hat >= 0.5, prob >= 0.5)\n",
    "            \n",
    "\n",
    "    \n",
    "    loss /= (nplays > 0).sum()/2\n",
    "    binary_loss /= (nplays > 0).sum()/2\n",
    "    \n",
    "    return loss, binary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = prediction_loss(skill_hat, nplayers_val, nplays_val, nwins_val, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26739516078822506, 0.18093319906008729)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_per_game(skill, games):\n",
    "    \n",
    "    loss = 0.\n",
    "    \n",
    "    for game in games:\n",
    "        a, b, w, sa, sb = game\n",
    "        prob_hat = logit( skill_data['scale']*(skill[:,a]-skill[:,b]) ).mean()\n",
    "        loss += np.logical_xor(prob_hat >= 0.5, w)\n",
    "        \n",
    "    loss /= len(games)*2\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21798365122615804"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_per_game(skill_hat, games_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
